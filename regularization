#import
import numpy as np
from keras.datasets import mnist
from keras.utils import np_utils
from keras.models import Sequential
from keras.layers import Dense
from tensorflow.keras.optimizers import Adam,Nadam, SGD
from keras.regularizers import l2
#read in

(x_train,y_train), (x_test,y_test) = mnist.load_data()

#check
print('x_shape:', x_train.shape)

print('y_shape:', y_train.shape)


#normal
x_train = x_train.reshape(x_train.shape[0], -1)/255.0
x_test = x_test.reshape(x_test.shape[0], -1)/255.0

y_train = np_utils.to_categorical(y_train, num_classes=10)
y_test = np_utils.to_categorical(y_test, num_classes=10)

#model
model = Sequential([
        Dense(units=200, input_dim=784, bias_initializer='one', activation='relu', kernel_regularizer=l2(0.0003)),
        Dense(units=100, bias_initializer='one', activation='relu', kernel_regularizer=l2(0.0003)),
        Dense(units=10, bias_initializer='one', activation='softmax', kernel_regularizer=l2(0.0003))
    ])

# optimizer
sgd = SGD(lr=0.2)

# loss function
model.compile(
    optimizer = sgd,
    loss = 'categorical_crossentropy',
    metrics = ['accuracy']
)

# train
model.fit(x_train, y_train, batch_size=32, epochs=10)


# assess
loss, accuracy = model.evaluate(x_test, y_test)
print('\ntest loss:', loss)
print('test accuracy:', accuracy)

loss, accuracy = model.evaluate(x_train, y_train)
print('\ntrain loss:', loss)
print('train accuracy:', accuracy)
